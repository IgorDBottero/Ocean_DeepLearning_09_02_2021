{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Itroducaopython_Ocean_deeplearning_09_02_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNf5KPjTjd3szoD72kD5FUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IgorDBottero/Ocean_DeepLearning_09_02_2021/blob/main/Itroducaopython_Ocean_deeplearning_09_02_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9rfDwoj0kG0"
      },
      "source": [
        "import keras # Importa a biblioteca Keras\r\n",
        "from keras.datasets import mnist # Base de Dados MNIST\r\n",
        "from tensorflow.python.keras import Sequential # Arquitetura da nossa rede neura\r\n",
        "from tensorflow.python.keras.layers import Dense, Dropout # Neurônio (base da rede) e Regularizador (evita overfitting)\r\n",
        "from tensorflow.compat.v1.keras.optimizers import RMSprop # Otimizador (back propagation)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzAA5zy39d7q"
      },
      "source": [
        "#Carregando dados de treino e teste\r\n",
        "\r\n",
        "(x_treino, y_treino), (x_teste, y_teste) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ADN3iPS-3Zk",
        "outputId": "5575ee23-4197-4c8c-d0f4-345b51bd0281"
      },
      "source": [
        "print(\"quantidade de imgs para terino\", len(x_treino))\r\n",
        "\r\n",
        "print(\"quantidade de imgs para teste\", len(x_teste))\r\n",
        "\r\n",
        "print(\"tipo de x treino\", type(x_treino))\r\n",
        "\r\n",
        "primeira_imagem = x_treino[0]\r\n",
        "\r\n",
        "representacao_primeira_imagem = y_treino[0]\r\n",
        "\r\n",
        "print(\"a imagem é\", representacao_primeira_imagem)\r\n",
        "\r\n",
        "print(\"o formato dela é\", primeira_imagem.shape)\r\n",
        "\r\n",
        "print(primeira_imagem)\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quantidade de imgs para terino 60000\n",
            "quantidade de imgs para teste 10000\n",
            "tipo de x treino <class 'numpy.ndarray'>\n",
            "a imagem é 5\n",
            "o formato dela é (28, 28)\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "HAbbAeWA_Qdb",
        "outputId": "34907849-4a9d-4899-dc3f-96fd4e53a4b0"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "indice = 1000\r\n",
        "\r\n",
        "print(\"A imagem representa:\", y_treino[indice])\r\n",
        "\r\n",
        "plt.imshow(x_treino[indice])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A imagem representa: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd5f8213470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOLklEQVR4nO3de4xc9XnG8efBXttgTGJDMcaxwEVWGysqpqwMaSgiglCHXCAJQVg0opIbc01jlV4QtAp/NJKbJlDUJCATXEwFRGkSF0tBIeAQ0fSCWIixDU5iLqbYNTYpSYAE3/DbP/Y4WmDPb9Zz977fj7SamfPOmXl18MM5M7855+eIEIDx77BeNwCgOwg7kARhB5Ig7EAShB1IYmI332ySJ8cUTe3mWwKp7NKvtCd2e7RaS2G3vUjSzZImSPpaRCwvPX+Kpuo0n93KWwIoeCTW1taaPoy3PUHSVyR9UNJ8SYttz2/29QB0Viuf2RdKejoino2IPZK+Lun89rQFoN1aCftsSS+MeLy1WvYmtpfaHrI9tFe7W3g7AK3o+LfxEbEiIgYjYnBAkzv9dgBqtBL2bZLmjHj8rmoZgD7UStgflTTP9lzbkyRdLGlNe9oC0G5ND71FxD7bV0u6X8NDbysj4sm2dQagrVoaZ4+I+yTd16ZeAHQQP5cFkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgiZZmccX4d9iC+cX6T5YdXqxv/sBttbUJLu9rfr1/T7H+3i8uK9aPv/Xx2tr+XbuK645HLYXd9hZJr0p6Q9K+iBhsR1MA2q8de/b3R8TP2vA6ADqIz+xAEq2GPSR9z/ZjtpeO9gTbS20P2R7aq90tvh2AZrV6GH9GRGyzfaykB2z/OCIeHvmEiFghaYUkHeUZ0eL7AWhSS3v2iNhW3e6UtFrSwnY0BaD9mg677am2px24L+lcSRvb1RiA9mrlMH6mpNW2D7zO3RHx3bZ0hbbxxPJ/4v/9s/LB2Nc+c3OxfuqkCQfd0wH/sWt/sX765HLvj//ll4v1Dz90SX3xiU3FdcejpsMeEc9KOrmNvQDoIIbegCQIO5AEYQeSIOxAEoQdSIJTXMeBnVf+QW3tFwv2Ftd9+kPl4SupPLT2/o2fKNb333ZsbW3aj39ZXHf+qp8W6184bqhYP/qW7bW1l+o32bjFnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCc/RDwwt+UB4WfuOKfamuHycV11+3ZV6z/1ZIrivXDH6q/XLMkKZ6rLZVPcJU2nTO9/IQGV0/45xPW1tbOXXR5cd1J3320/OKHIPbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+x9YML08njyskv+rVgvjaVvf+PXxXX/4vLytMeTvl8+Z7yT4vXXi/Wv/mJusX7lO+vH+KP884NxiT07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHsf8PR3FOtLjtra9Gufee81xfq8+x9p+rU7bf+uXcX6nc+dVqxfeUr9OHtGDffstlfa3ml744hlM2w/YHtzddvgKgMAem0sh/F3SFr0lmXXSlobEfMkra0eA+hjDcMeEQ9Levkti8+XtKq6v0rSBW3uC0CbNfuZfWZEHJhI60VJM+ueaHuppKWSNEVHNPl2AFrV8rfxERGSolBfERGDETE4oMmtvh2AJjUb9h22Z0lSdbuzfS0B6IRmw75G0qXV/Usl3duedgB0SsPP7LbvkXSWpGNsb5X0OUnLJX3D9hJJz0u6qJNNjnd7Z72zpfW3Fc5Z/53bynOgN7p2O8aPhmGPiMU1pbPb3AuADuLnskAShB1IgrADSRB2IAnCDiTBKa594JkLp7S0/rn/XT+t8gnrN7T02hg/2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs3fBxNnHF+u3fOT2ll5/wo+mtbR+vzrsiPJlzD7/u6u71Mn4wJ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnL0LfnXy7GL97MN3t/T6k39eOyHPIc0Ty/88G223/9v/em1t4LV9TfV0KGPPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM4+Dsy8a2NtLfOUzKt++Xu1tcP+/Udd7KQ/NNyz215pe6ftjSOW3WB7m+111d95nW0TQKvGchh/h6RFoyy/KSIWVH/3tbctAO3WMOwR8bCkl7vQC4AOauULuqttr68O86fXPcn2UttDtof2qrXfgANoXrNhv0XSSZIWSNou6Ut1T4yIFRExGBGDA5rc5NsBaFVTYY+IHRHxRkTsl3SbpIXtbQtAuzUVdtuzRjz8mKT6sR8AfaHhOLvteySdJekY21slfU7SWbYXSApJWyRd1sEekdTzV72nwTN+UKzefesf1daO1X8efEOHuIZhj4jFoyxubVYDAF3Hz2WBJAg7kARhB5Ig7EAShB1IglNcu2DK2vXF+l2vHlusXzJtZzvb6RsT555QrH/lT29t6fWP/8622lq+C0mzZwfSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhn74LYXb4c166Y1KVO+suOc44v1v9wSnk0fHc0GC2P8TmVdbPYswNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyzjwcnzamvrXuqe32MYuIJ9b19/DPfL67baBz9vf+wrFg/bku+y0WXsGcHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZ+8Df3//R4v1JZ/8arH+zMXvqK3NXddUS2PmieV/Qk9df1xtbc3R9xbX/cGuw4v1425mHP1gNNyz255j+yHbT9l+0vZnq+UzbD9ge3N1O73z7QJo1lgO4/dJuiYi5ks6XdJVtudLulbS2oiYJ2lt9RhAn2oY9ojYHhGPV/dflbRJ0mxJ50taVT1tlaQLOtUkgNYd1Gd22ydKOkXSI5JmRsT2qvSipJk16yyVtFSSpuiIZvsE0KIxfxtv+0hJ35K0LCJeGVmLiJA06tX9ImJFRAxGxOCAJrfULIDmjSnstgc0HPS7IuLb1eIdtmdV9VmSxudUo8A40fAw3rYl3S5pU0TcOKK0RtKlkpZXt+VxFNSavtHlJ3yyXP67j99dW1v1j6cX19334o7yizew4/KFxfrTH/pybW3Dnr3FdT9/2aeL9QE9Vqzjzcbymf19kj4laYPtA6O212k45N+wvUTS85Iu6kyLANqhYdgj4oeS6nY9Z7e3HQCdws9lgSQIO5AEYQeSIOxAEoQdSIJTXPvAzO88V6yvu758SeVPTP15be3avz2xuO67lw8U65uvLFymWtI3F99YrEv101Ff+M3ypaBPevC/Grw2DgZ7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1IwsMXmemOozwjTjMnyh2sveecWqyvvqP+nPEjXb460GN73ijWT64fJpckTdSEYv3MDRfW1qZ9+H+K68a+8u8L8HaPxFq9Ei+PepYqe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSILz2Q8BAw+Wr4++8I4/r6396x/fVFz31EkNBtIbmLf6imL93cu31tb2MY7eVezZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJhuez254j6U5JMyWFpBURcbPtGyR9WtJL1VOvi4j7Sq/F+exAZ5XOZx/Lj2r2SbomIh63PU3SY7YfqGo3RcQX29UogM4Zy/zs2yVtr+6/anuTpNmdbgxAex3UZ3bbJ0o6RdIj1aKrba+3vdL29Jp1ltoesj20V7tbahZA88YcdttHSvqWpGUR8YqkWySdJGmBhvf8XxptvYhYERGDETE4oPL10AB0zpjCbntAw0G/KyK+LUkRsSMi3oiI/ZJuk7Swc20CaFXDsNu2pNslbYqIG0csnzXiaR+TtLH97QFol7F8G/8+SZ+StMH2umrZdZIW216g4eG4LZIu60iHANpiLN/G/1DSaON2xTF1AP2FX9ABSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSaHgp6ba+mf2SpOdHLDpG0s+61sDB6dfe+rUvid6a1c7eToiI3xqt0NWwv+3N7aGIGOxZAwX92lu/9iXRW7O61RuH8UAShB1IotdhX9Hj9y/p1976tS+J3prVld56+pkdQPf0es8OoEsIO5BET8Jue5Htn9h+2va1veihju0ttjfYXmd7qMe9rLS90/bGEctm2H7A9ubqdtQ59nrU2w22t1Xbbp3t83rU2xzbD9l+yvaTtj9bLe/ptiv01ZXt1vXP7LYnSPqppA9I2irpUUmLI+KprjZSw/YWSYMR0fMfYNg+U9Jrku6MiPdUy74g6eWIWF79j3J6RPx1n/R2g6TXej2NdzVb0ayR04xLukDSn6iH267Q10XqwnbrxZ59oaSnI+LZiNgj6euSzu9BH30vIh6W9PJbFp8vaVV1f5WG/7F0XU1vfSEitkfE49X9VyUdmGa8p9uu0FdX9CLssyW9MOLxVvXXfO8h6Xu2H7O9tNfNjGJmRGyv7r8oaWYvmxlFw2m8u+kt04z3zbZrZvrzVvEF3dudERG/L+mDkq6qDlf7Ugx/BuunsdMxTePdLaNMM/4bvdx2zU5/3qpehH2bpDkjHr+rWtYXImJbdbtT0mr131TUOw7MoFvd7uxxP7/RT9N4jzbNuPpg2/Vy+vNehP1RSfNsz7U9SdLFktb0oI+3sT21+uJEtqdKOlf9NxX1GkmXVvcvlXRvD3t5k36ZxrtumnH1eNv1fPrziOj6n6TzNPyN/DOSru9FDzV9/bakJ6q/J3vdm6R7NHxYt1fD320skXS0pLWSNkt6UNKMPurtXyRtkLRew8Ga1aPeztDwIfp6Seuqv/N6ve0KfXVlu/FzWSAJvqADkiDsQBKEHUiCsANJEHYgCcIOJEHYgST+Hy23KaACXHBZAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4XN6Ft4EwT4"
      },
      "source": [
        "# Fluxo para construção de rede neural\r\n",
        "# - Organizar a camada de entrada (input)\r\n",
        "# - Organizar a camada de saída (output)\r\n",
        "# - Estruturar a nossa rede neural\r\n",
        "# - Treinar o modelo\r\n",
        "# - Fazer as previsões\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpvomcrHE7Os"
      },
      "source": [
        "# achatando a matriz de pixels e transformando em uma unica lista\r\n",
        "\r\n",
        "quantidade_treino = len(x_treino) #60000\r\n",
        "quantidade_teste = len(y_teste) # 10000\r\n",
        "\r\n",
        "resolucao_imagem = x_treino[0].shape # (28,28)\r\n",
        "\r\n",
        "resolucao_total = resolucao_imagem[0] * resolucao_imagem[1] # 28 * 28 = 784\r\n",
        "\r\n",
        "x_treino = x_treino.reshape(quantidade_treino, resolucao_total)\r\n",
        "x_teste = x_teste.reshape(quantidade_teste, resolucao_total)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkpM7PeOGeoe",
        "outputId": "1c37aa7f-3b4f-4fa8-9d2a-5fefca79ab99"
      },
      "source": [
        "print(\"quantidade de itens em x_treino .achatado[0]\", len(x_treino[0]))\r\n",
        "\r\n",
        "print(x_treino[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quantidade de itens em x_treino .achatado[0] 784\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
            " 247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
            " 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
            "   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
            "  82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
            " 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
            " 225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            " 253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
            " 253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
            "  80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0gGGMRTNRQ1"
      },
      "source": [
        "\"\"\"\r\n",
        "Normalização dos dados\r\n",
        "\r\n",
        "255 vire 1\r\n",
        "127 vire 0.5\r\n",
        "0 vire 0\r\n",
        "e por assim diante\r\n",
        "\r\n",
        "\"\"\"\r\n",
        "x_treino = x_treino.astype('float32') #converte toda a base de unit_8 para float32\r\n",
        "x_teste = x_teste.astype('float32') #converte toda a base de unit_8 para float32\r\n",
        "\r\n",
        "\r\n",
        "x_treino /= 255 #Divide todos o 60000 valores de x_treino por 255 e armazena o resultado direto em x_treino\r\n",
        "x_teste /= 255  #Divide todos o 10000 valores de x_treino por 255 e armazena o resultado direto em x_teste"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iigNM3jO-GV",
        "outputId": "462f894d-56ad-43b6-f2c7-a39c42f4ce7c"
      },
      "source": [
        "print(x_treino[0][350], type(x_treino[0][350]))\r\n",
        "\r\n",
        "print(x_treino[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.27450982 <class 'numpy.float32'>\n",
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215687\n",
            " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313726\n",
            " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13725491 0.94509804\n",
            " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            " 0.5882353  0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.5803922\n",
            " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058825\n",
            " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            " 0.3137255  0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333336 0.99215686\n",
            " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFDqX23eTSbT",
        "outputId": "f9fb206e-a167-43ec-a19f-2ff3cdacffe5"
      },
      "source": [
        "\r\n",
        "# Preparação da camada de saída (output)\r\n",
        "\r\n",
        "# Quais são as possibilidades de saída? Números de 0 a 9\r\n",
        "# Quantos itens temos? 10 itens\r\n",
        "# Números  -> [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\r\n",
        "# Número 0 -> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "# Número 1 -> [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\r\n",
        "# Número 9 -> [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\r\n",
        "\r\n",
        "valores_unicos = set(y_treino) # {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\r\n",
        "print(valores_unicos)\r\n",
        "\r\n",
        "quantidade_valores_unicos = len(valores_unicos) # 10\r\n",
        "print(quantidade_valores_unicos)\r\n",
        "\r\n",
        "print(\"y_treino[0] antes:\", y_treino[0])\r\n",
        "\r\n",
        "y_treino = keras.utils.to_categorical(y_treino, quantidade_valores_unicos)\r\n",
        "y_teste = keras.utils.to_categorical(y_teste, quantidade_valores_unicos)\r\n",
        "\r\n",
        "print(\"y_treino[0] depois:\", y_treino[0])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "10\n",
            "y_treino[0] antes: 5\n",
            "y_treino[0] depois: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-CIBJviV5UE",
        "outputId": "2443c709-76d2-474f-800d-4e7343be9848"
      },
      "source": [
        "# Criando o modelo da rede neural\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "# Primeira hidden layer\r\n",
        "# 30 neurônios\r\n",
        "# Função de ativação: ReLU\r\n",
        "# Como estamos na primeira hidden layer, precisamos informar o formato da camada de entrada (input)\r\n",
        "\r\n",
        "model.add(Dense(30, activation='relu', input_shape=(resolucao_total,)))\r\n",
        "\r\n",
        "# Adicionamos um regularizador, que ajuda a evitar o overfitting\r\n",
        "# No caso, será o Dropout\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "# Segunda hidden layer\r\n",
        "# 20 neurônios\r\n",
        "# Função de ativação: ReLU\r\n",
        "\r\n",
        "model.add(Dense(20, activation='relu'))\r\n",
        "\r\n",
        "# Mais um regularizador depois da segunda hidden layer\r\n",
        "model.add(Dropout(0.2))\r\n",
        "\r\n",
        "# Finalizamos com a camada de saída (output), informando a quantidade de valores únicos que, no caso, é 10\r\n",
        "# Função de ativação: Como ReLU deve usada apenas nas hidden layers, iremos utilizar a função Softmax\r\n",
        "model.add(Dense(quantidade_valores_unicos, activation='softmax'))\r\n",
        "\r\n",
        "# Exibe o resumo do modelo criado\r\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                620       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 24,380\n",
            "Trainable params: 24,380\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4nvwd4FZ3gN",
        "outputId": "02b00c58-5f6b-40ca-e7bf-44b268c67104"
      },
      "source": [
        "## Compila e treina o modelo\r\n",
        "# Precisamos informar qual será:\r\n",
        "# Função de erro\r\n",
        "# Algoritmo de backpropagation\r\n",
        "# Dados para Treino (imagens normalizadas e labels categorizadas)\r\n",
        "# Dados para Teste (imagens normalizadas e labels categorizadas)\r\n",
        "# Quantidade de épocas que queremos rodar (sendo 1 época equivalente a analisar TODAS as imagens de treino)\r\n",
        "# Tamanho de cada 'batch'\r\n",
        "#   -> Supondo que temos 100 imagens\r\n",
        "#   -> 100 imagens pode ser muito pesado para processar de uma única vez\r\n",
        "#   -> Portanto, quebramos em 'batches' de 10 imagens, cada, e processamos 10 imagens por vez\r\n",
        "#   -> Geralmente, o tamanho dos batches deve ser potência de 2 (2, 4, 8, 16, 32, 64, 128, ...), para melhorar performance\r\n",
        "\r\n",
        "model.compile(loss='categorical_crossentropy',\r\n",
        "              optimizer=RMSprop(),\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "# Treina o modelo\r\n",
        "\r\n",
        "history = model.fit(x_treino, y_treino,\r\n",
        "                    batch_size=128,\r\n",
        "                    epochs=10,\r\n",
        "                    verbose=1,\r\n",
        "                    validation_data=(x_teste, y_teste))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 1.2204 - accuracy: 0.6007 - val_loss: 0.3127 - val_accuracy: 0.9130\n",
            "Epoch 2/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.5020 - accuracy: 0.8479 - val_loss: 0.2438 - val_accuracy: 0.9290\n",
            "Epoch 3/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.4109 - accuracy: 0.8748 - val_loss: 0.2173 - val_accuracy: 0.9359\n",
            "Epoch 4/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3705 - accuracy: 0.8885 - val_loss: 0.1973 - val_accuracy: 0.9425\n",
            "Epoch 5/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3285 - accuracy: 0.9046 - val_loss: 0.1916 - val_accuracy: 0.9440\n",
            "Epoch 6/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3118 - accuracy: 0.9051 - val_loss: 0.1802 - val_accuracy: 0.9450\n",
            "Epoch 7/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.3063 - accuracy: 0.9109 - val_loss: 0.1714 - val_accuracy: 0.9493\n",
            "Epoch 8/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2909 - accuracy: 0.9141 - val_loss: 0.1689 - val_accuracy: 0.9510\n",
            "Epoch 9/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2738 - accuracy: 0.9174 - val_loss: 0.1671 - val_accuracy: 0.9526\n",
            "Epoch 10/10\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.2706 - accuracy: 0.9192 - val_loss: 0.1649 - val_accuracy: 0.9536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "9OYLaKbpeJ6k",
        "outputId": "3ac09813-be26-4b42-f8ab-9f0b695d36d0"
      },
      "source": [
        "# Fazendo nossas previsões\r\n",
        "\r\n",
        "indice = 1234\r\n",
        "\r\n",
        "print(\"Valor categórico em y_teste[indice]:\", y_teste[indice])\r\n",
        "\r\n",
        "# Como o model.predict aceita mais de uma imagem ao mesmo tempo\r\n",
        "# e queremos apenas analisar uma imagem, precisamos fazer um reshape, em que [0, 0, 0, 0], vira [[0, 0, 0, 0]]\r\n",
        "imagem = x_teste[indice].reshape((1, resolucao_total))\r\n",
        "\r\n",
        "# Fazemos a previsão da imagem\r\n",
        "prediction = model.predict(imagem)\r\n",
        "print(\"Previsão:\", prediction)\r\n",
        "\r\n",
        "# Transformar a previsão em algo que conseguimos entender de forma mais fácil\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "# Convertemos a previsão que está em porcentagens, pegando o maior valor disponível\r\n",
        "prediction_class = np.argmax(prediction, axis=-1)\r\n",
        "print(\"Previsão ajustada:\", prediction_class)\r\n",
        "\r\n",
        "# Recarregamos o MNIST e exibimos a imagem original usando o matplotlib carregado anteriormente\r\n",
        "(x_treino_img, y_treino_img), (x_teste_img, y_teste_img) = mnist.load_data()\r\n",
        "plt.imshow(x_teste_img[indice], cmap=plt.cm.binary)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valor categórico em y_teste[indice]: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "Previsão: [[1.4645365e-03 4.1712471e-03 3.7810452e-02 1.4183280e-01 5.3617492e-04\n",
            "  1.5502620e-01 4.4736973e-04 7.5817964e-04 6.4995426e-01 7.9987524e-03]]\n",
            "Previsão ajustada: [8]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fd5e8c667b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw_5T8QAeCc6"
      },
      "source": [
        "#matrix = metrics.confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}